<!doctype html><html lang=en class="js csstransforms3d"><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.112.3"><meta name=description content="Official documentation for DIAMBRA, the platform where coders create AI agents to compete in video games tournaments."><meta name=author content="DIAMBRA Team"><meta name=keywords content="Documentation,Reinforcement Learning,Deep Reinforcement Learning,AI Tournaments,Video Games Environments,RL Environments,DIAMBRA,DIAMBRA Documentation,AI Competitions,Artificial Intelligence"><meta itemprop=name content="DIAMBRA Docs"><meta itemprop=description content="Official documentation for DIAMBRA, the platform where coders create AI agents to compete in video games tournaments."><meta itemprop=image content="https://docs.diambra.ai//images/logoMeta.png"><meta property="og:site_name" content="DIAMBRA Docs"><meta property="og:title" content="DIAMBRA Docs"><meta property="og:description" content="Official documentation for DIAMBRA, the platform where coders create AI agents to compete in video games tournaments."><meta property="og:image" content="https://docs.diambra.ai//images/logoMeta.png"><meta property="og:url" content="https://docs.diambra.ai"><meta property="og:type" content="website"><meta name=publish_date property="og:publish_date" content="2022-01-15T00:00:00-0600"><meta charset=utf-8><link rel=icon href=/images/favicon.png type=image/png><title>Hands-on Reinforcement Learning :: DIAMBRA Docs</title><link href=/css/nucleus.css?1718070586 rel=stylesheet><link href=/css/fontawesome-all.min.css?1718070586 rel=stylesheet><link href=/css/hybrid.css?1718070586 rel=stylesheet><link href=/css/featherlight.min.css?1718070586 rel=stylesheet><link href=/css/perfect-scrollbar.min.css?1718070586 rel=stylesheet><link href=/css/auto-complete.css?1718070586 rel=stylesheet><link href=/css/atom-one-dark-reasonable.css?1718070586 rel=stylesheet><link href=/css/theme.css?1718070586 rel=stylesheet><link href=/css/tabs.css?1718070586 rel=stylesheet><link href=/css/hugo-theme.css?1718070586 rel=stylesheet><link href=/css/theme-diambra.css?1718070586 rel=stylesheet><script src=/js/jquery-3.3.1.min.js?1718070586></script><style>:root #header+#content>#left>#rlblock_left{display:none!important}</style><style type=text/css>pre code{white-space:pre}</style></head><body data-url=/handsonreinforcementlearning/><nav id=sidebar class=showVisitedLinks><div id=header-wrapper><div id=header><a id=logo href=https://docs.diambra.ai/><img src=https://docs.diambra.ai//images/logo.png></a></div><div class=searchbox><label for=search-by><i class="fas fa-search"></i></label>
<input data-search-input id=search-by type=search placeholder=Search...>
<span data-search-clear><i class="fas fa-times"></i></span></div><script type=text/javascript src=/js/lunr.min.js?1718070586></script>
<script type=text/javascript src=/js/auto-complete.js?1718070586></script>
<script type=text/javascript>var baseurl="https://docs.diambra.ai/"</script><script type=text/javascript src=/js/search.js?1718070586></script></div><section id=homelinks><ul><li><a class=padding href=https://docs.diambra.ai/><i class='fas fa-home'></i> Home</a></li></ul></section><section id=versions class=dropdown><a class=dropdown-toggle>Versions â–¼</a><div class=dropdown-content><a href=/>Latest</a>
<a href=/v2.1>2.1</a></div></section><div class=highlightable><ul class=topics><li data-nav-id=/gettingstarted/ title="Getting Started" class=dd-item><a href=/gettingstarted/>Getting Started
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/gettingstarted/examples/ title=Examples class=dd-item><a href=/gettingstarted/examples/>Examples
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/gettingstarted/examples/singleplayerenv/ title="Single Player Environment" class=dd-item><a href=/gettingstarted/examples/singleplayerenv/>Single Player Environment
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/gettingstarted/examples/multiplayerenv/ title="Multi Player Environment" class=dd-item><a href=/gettingstarted/examples/multiplayerenv/>Multi Player Environment
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/gettingstarted/examples/wrappersoptions/ title="Wrappers Options" class=dd-item><a href=/gettingstarted/examples/wrappersoptions/>Wrappers Options
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/gettingstarted/examples/episoderecorder/ title="Episode Recorder" class=dd-item><a href=/gettingstarted/examples/episoderecorder/>Episode Recorder
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/gettingstarted/examples/datasetloader/ title="Dataset Loader" class=dd-item><a href=/gettingstarted/examples/datasetloader/>Dataset Loader
<i class="fas fa-check read-icon"></i></a></li></ul></li></ul></li><li data-nav-id=/envs/ title=Environments class=dd-item><a href=/envs/>Environments
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/envs/games/ title="Games & Specifics" class=dd-item><a href=/envs/games/>Games & Specifics
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/envs/games/doapp/ title="Dead Or Alive ++" class=dd-item><a href=/envs/games/doapp/>Dead Or Alive ++
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/envs/games/sfiii3n/ title="Street Fighter III 3rd Strike" class=dd-item><a href=/envs/games/sfiii3n/>Street Fighter III 3rd Strike
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/envs/games/tektagt/ title="Tekken Tag Tournament" class=dd-item><a href=/envs/games/tektagt/>Tekken Tag Tournament
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/envs/games/umk3/ title="Ultimate Mortal Kombat 3" class=dd-item><a href=/envs/games/umk3/>Ultimate Mortal Kombat 3
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/envs/games/samsh5sp/ title="Samurai Showdown 5 Special" class=dd-item><a href=/envs/games/samsh5sp/>Samurai Showdown 5 Special
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/envs/games/kof98umh/ title="The King of Fighers '98 UMH" class=dd-item><a href=/envs/games/kof98umh/>The King of Fighers '98 UMH
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/envs/games/mvsc/ title="Marvel VS Capcom" class=dd-item><a href=/envs/games/mvsc/>Marvel VS Capcom
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/envs/games/xmvsf/ title="X-Men VS Street Fighter" class=dd-item><a href=/envs/games/xmvsf/>X-Men VS Street Fighter
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/envs/games/soulclbr/ title="Soul Calibur" class=dd-item><a href=/envs/games/soulclbr/>Soul Calibur
<i class="fas fa-check read-icon"></i></a></li></ul></li></ul></li><li data-nav-id=/wrappers/ title=Wrappers class=dd-item><a href=/wrappers/>Wrappers
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/utils/ title=Utils class=dd-item><a href=/utils/>Utils
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/imitationlearning/ title="Imitation Learning" class=dd-item><a href=/imitationlearning/>Imitation Learning
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/handsonreinforcementlearning/ title="Hands-on Reinforcement Learning" class="dd-item
active"><a href=/handsonreinforcementlearning/>Hands-on Reinforcement Learning
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/handsonreinforcementlearning/sheeprl/ title=SheepRL class=dd-item><a href=/handsonreinforcementlearning/sheeprl/>SheepRL
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/handsonreinforcementlearning/stablebaselines3/ title="Stable Baselines 3" class=dd-item><a href=/handsonreinforcementlearning/stablebaselines3/>Stable Baselines 3
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/handsonreinforcementlearning/rayrllib/ title="Ray RLlib" class=dd-item><a href=/handsonreinforcementlearning/rayrllib/>Ray RLlib
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/competitionplatform/ title="Competition Platform" class=dd-item><a href=/competitionplatform/>Competition Platform
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/competitionplatform/basicagentscript/ title="Basic Agent Script" class=dd-item><a href=/competitionplatform/basicagentscript/>Basic Agent Script
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/competitionplatform/submissionevaluation/ title="Submission Evaluation" class=dd-item><a href=/competitionplatform/submissionevaluation/>Submission Evaluation
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/competitionplatform/howtosubmitanagent/ title="How To Submit An Agent" class=dd-item><a href=/competitionplatform/howtosubmitanagent/>How To Submit An Agent
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/competitionplatform/howtosubmitanagent/submitprebuiltagents/ title="Submit Pre-Built Agents" class=dd-item><a href=/competitionplatform/howtosubmitanagent/submitprebuiltagents/>Submit Pre-Built Agents
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/competitionplatform/howtosubmitanagent/submityourownagent/ title="Submit Your Own Agent" class=dd-item><a href=/competitionplatform/howtosubmitanagent/submityourownagent/>Submit Your Own Agent
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/competitionplatform/howtosubmitanagent/customdependenciesimage/ title="Custom Dependencies Image" class=dd-item><a href=/competitionplatform/howtosubmitanagent/customdependenciesimage/>Custom Dependencies Image
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/competitionplatform/argumentsandcommands/ title="Arguments and Commands" class=dd-item><a href=/competitionplatform/argumentsandcommands/>Arguments and Commands
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/competitionplatform/testyouragentlocally/ title="Test Your Agent Locally" class=dd-item><a href=/competitionplatform/testyouragentlocally/>Test Your Agent Locally
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/projects/ title=Projects class=dd-item><a href=/projects/>Projects
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/projects/llmcolosseum/ title="LLM Colosseum" class=dd-item><a href=/projects/llmcolosseum/>LLM Colosseum
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/projects/marlleaguetraining/ title="MARL - League Training" class=dd-item><a href=/projects/marlleaguetraining/>MARL - League Training
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/projects/rlztournament/ title="RLZ Tournament" class=dd-item><a href=/projects/rlztournament/>RLZ Tournament
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/projects/gamepainter/ title="Game Painter" class=dd-item><a href=/projects/gamepainter/>Game Painter
<i class="fas fa-check read-icon"></i></a></li></ul></li></ul><section id=shortcuts><h3>More</h3><ul><li><a class=padding href=https://diambra.ai target=_blank><i class='fas fa-globe'></i> Website</a></li><li><a class=padding href=https://github.com/diambra/ target=_blank><i class='fab fa-fw fa-github'></i> GitHub</a></li><li><a class=padding href=https://diambra.ai/discord target=_blank><i class='fab fa-discord'></i> Discord</a></li><li><a class=padding href=https://www.twitch.tv/diambra_ai target=_blank><i class='fab fa-twitch'></i> Twitch</a></li><li><a class=padding href=https://www.linkedin.com/company/diambra target=_blank><i class='fab fa-linkedin'></i> Linkedin</a></li><li><a class=padding href=https://www.youtube.com/c/diambra_ai target=_blank><i class='fab fa-youtube'></i> YouTube</a></li><li><a class=padding href=https://twitter.com/diambra_ai target=_blank><i class='fab fa-fw fa-twitter'></i> Twitter</a></li></ul></section><section id=prefooter><hr><ul><li><a class=padding href=# data-clear-history-toggle><i class="fas fa-history fa-fw"></i> Clear History</a></li></ul></section><section id=footer><center><a class=github-button href=https://github.com/diambra/arena/archive/refs/heads/main.zip data-icon=octicon-download aria-label="Download DIAMBRA Arena from GitHub">Download</a>
<a class=github-button href=https://github.com/diambra/arena data-icon=octicon-star data-show-count=true aria-label="Star DIAMBRA Arena on GitHub">Star</a>
<a class=github-button href=https://github.com/diambra/arena/fork data-icon=octicon-repo-forked data-show-count=true aria-label="Fork DIAMBRA Arena on GitHub">Fork</a></center>
<script async defer src=https://buttons.github.io/buttons.js></script></section></div></nav><section id=body><div id=overlay></div><div class="padding highlightable"><div><div id=top-bar><div id=breadcrumbs itemscope itemtype=http://data-vocabulary.org/Breadcrumb><span id=sidebar-toggle-span><a href=# id=sidebar-toggle data-sidebar-toggle><i class="fas fa-bars"></i></a></span>
<span id=toc-menu><i class="fas fa-list-alt"></i></span>
<span class=links><a href=/>Home</a> > Hands-on Reinforcement Learning</span></div><div class=progress><div class=wrapper><nav id=TableOfContents><ul><li><ul><li><a href=#index>Index</a></li><li><a href=#learning-reinforcement-learning>Learning Reinforcement Learning</a></li><li><a href=#end-to-end-deep-reinforcement-learning>End-to-End Deep Reinforcement Learning</a></li></ul></li></ul></nav></div></div></div></div><div id=head-tags></div><div id=body-inner><h1>Hands-on Reinforcement Learning</h1><h3 id=index>Index</h3><div style=font-size:1.125rem><ul><li><a href=./#learning-reinforcement-learning>Learning RL</a></li><li><a href=./#end-to-end-deep-reinforcement-learning>End-To-End DeepRL</a></li></ul></div><p>What is the best path leading a passionate coder to the creation of a trained AI agent capable of effectively playing a video game? It consists in two steps: learning reinforcement learning and applying it.</p><p><a href=./#learning-reinforcement-learning>Learning RL</a> section below deals with how to get started with RL: it presents resources that cover the basics and the most advanced details of the latest, best-performing algorithms.</p><p>Then, in the <a href=./#end-to-end-deep-reinforcement-learning>End-to-end Deep Reinforcement Learning</a> section, some of the most important tech tools are presented together with a step-by-step guide showing how to successfully train a Deep RL agent in our environments.</p><h3 id=learning-reinforcement-learning>Learning Reinforcement Learning</h3><h4 id=books>Books</h4><p>The first suggested step is to learn the basics of Reinforcement Learning. The best option to do so is Sutton & Barto&rsquo;s book &ldquo;Reinforcement Learning: An Introduction&rdquo;, that can be considered the reference text for the field. An additional option is Packt&rsquo;s &ldquo;The Reinforcement Learning Workshop&rdquo; that covers theory but also a good amount of practice, being very hands-on and complemented by a GitHub repo with worked exercises.</p><div><figure style=margin-top:0;margin-bottom:40px;margin-right:1%;margin-left:15%;float:left;width:35%><img style=margin-bottom:20px;border-radius:10px src=../../images/deepRlTraining/books_rlintro.png><figcaption align=middle>Reinforcement Learning: An Introduction - Sutton & Barto â€¢ <a href=https://mitpress.mit.edu/books/reinforcement-learning-second-edition target=_blank>Link</a></figcaption></figure><figure style=margin-top:0;margin-bottom:40px;margin-right:auto;margin-left:1%;float:left;width:35%><img style=margin-bottom:20px;border-radius:10px src=../../images/deepRlTraining/books_rlworkshop.png><figcaption align=middle>The Reinforcement Learning Workshop - Palmas et al. â€¢ <a href=https://www.packtpub.com/product/the-reinforcement-learning-workshop/9781800200456 target=_blank>Link</a></figcaption></figure></div><h4 id=courses--video-lectures>Courses / Video-lectures</h4><p>An additional useful resource is represented by courses and/or video-lectures. The four listed in this paragraph, in particular, are extremely valuable. The first one, &ldquo;DeepMind Deep RL at UCL &ldquo;, is a collection of lectures dealing with RL in general, as Sutton & Barto&rsquo;s book, providing the solid foundations of the field. The second one, &ldquo;Hugging Face Deep RL Course&rdquo;, teaches you about Deep Reinforcement Learning from beginner to expert and provides a certification of completion. The third one, &ldquo;OpenAI Spinning Up with Deep RL&rdquo;, is a very useful website providing a step-by-step primer focused on Deep RL, guiding the reader from the basics to understanding the most important algorithms down to the implementation details. The fourth one, &ldquo;Berkeley Deep RL Bootcamp&rdquo;, provides video and slides dealing specifically with Deep RL too, and presents a wide overview of the most important, state-of-the-art methods in the field. These are all extremely useful and available for free.</p><div><figure style=margin-top:0;margin-bottom:40px;margin-right:1%;margin-left:2%;float:left;width:22%><img style=margin-bottom:20px;border-radius:10px src=../../images/deepRlTraining/courses_deepminducl.png><figcaption align=middle>DeepMind Deep RL at UCL â€¢ <a href=https://www.deepmind.com/learning-resources/reinforcement-learning-lecture-series-2021 target=_blank>Link</a></figcaption></figure><figure style=margin-top:0;margin-bottom:40px;margin-right:1%;margin-left:1%;float:left;width:22%><img style=margin-bottom:20px;border-radius:10px src=../../images/deepRlTraining/courses_hf.png><figcaption align=middle>Hugging Face Deep RL Course â€¢ <a href=https://huggingface.co/learn/deep-rl-course/unit0/introduction target=_blank>Link</a></figcaption></figure><figure style=margin-top:0;margin-bottom:40px;margin-right:1%;margin-left:1%;float:left;width:22%><img style=margin-bottom:20px;border-radius:10px src=../../images/deepRlTraining/courses_spinningup.jpg><figcaption align=middle>OpenAI Spinning Up with Deep RL â€¢ <a href=https://spinningup.openai.com/en/latest/ target=_blank>Link</a></figcaption></figure><figure style=margin-top:0;margin-bottom:40px;margin-right:auto;margin-left:1%;float:left;width:22%><img style=margin-bottom:20px;border-radius:10px src=../../images/deepRlTraining/courses_deepRlBoot.png><figcaption align=middle>Berkeley Deep RL Bootcamp â€¢ <a href=https://sites.google.com/view/deep-rl-bootcamp/lectures target=_blank>Link</a></figcaption></figure></div><h4 id=research-publications>Research Publications</h4><p>After having acquired solid fundamentals, as usual in the whole ML domain, one should rely on publications to keep the pace of field advancements. Conference papers, peer-reviewed journal and open access publications are all options to consider.</p><p>A good starting point is to read the reference paper for all state-of-the-art algorithms implemented in the most important <a href=/handsonreinforcementlearning/#reinforcement-learning-libraries>RL libraries (see next section)</a>, as found for example <a href=https://stable-baselines3.readthedocs.io/en/master/guide/algos.html target=_blank>here (SB3)</a> and <a href=https://docs.ray.io/en/latest/rllib/rllib-algorithms.html target=_blank>here (RAY RLlib)</a>.</p><div><figure style=margin-top:0;margin-bottom:40px;margin-right:1%;margin-left:3%;float:left;width:30%><img style=margin-bottom:20px;border-radius:10px src=../../images/deepRlTraining/papers_arxiv.png><figcaption align=middle>Open Access<br>(<a href=https://arxiv.org/search/cs target=_blank>Arxiv</a>, etc.)</figcaption></figure><figure style=margin-top:0;margin-bottom:40px;margin-right:1%;margin-left:1%;float:left;width:30%><img style=margin-bottom:20px;border-radius:10px src=../../images/deepRlTraining/papers_conferences.png><figcaption align=middle>International Conferences<br>(<a href=https://icml.cc/ target=_blank>ICML</a>, <a href=https://nips.cc/ target=_blank>NeurIPS</a>, <a href=https://iclr.cc/ target=_blank>ICLR</a>, etc.)</figcaption></figure><figure style=margin-top:0;margin-bottom:40px;margin-right:auto;margin-left:1%;float:left;width:30%><img style=margin-bottom:20px;border-radius:10px src=../../images/deepRlTraining/papers_journals.png><figcaption align=middle>Peer-reviewed Journals<br>(<a href=https://www.sciencedirect.com/journal/artificial-intelligence target=_blank>ELSEVIER</a>, <a href=https://www.springer.com/journal/10458 target=_blank>Springer</a>, etc.)</figcaption></figure></div><h4 id=more>More</h4><p>Finally, additional sources of useful information to better understand this field, and to get inspired by its great potential, are documentaries presenting notable milestones achieved by some of the best AI labs in the world. They showcase reinforcement learning masterpieces, such as AlphaGo/AlphaZero, OpenAI Five and Gran Turismo Sophy, mastering the games of Go, DOTA 2 and Gran TurismoÂ® 7 respectively.</p><div><figure style=margin-top:0;margin-bottom:40px;margin-right:1%;margin-left:3%;float:left;width:30%><img style=margin-bottom:20px;border-radius:10px src=../../images/deepRlTraining/film_alphago.png><figcaption align=middle>DeepMind<br>AlphaGo The Movie â€¢ <a href="https://www.youtube.com/watch?v=WXuK6gekU1Y" target=_blank>Link</a></figcaption></figure><figure style=margin-top:0;margin-bottom:40px;margin-right:1%;margin-left:1%;float:left;width:30%><img style=margin-bottom:20px;border-radius:10px src=../../images/deepRlTraining/film_artificialGamer.jpg><figcaption align=middle>OpenAI<br>Artificial Gamer â€¢ <a href="https://youtu.be/J0KPNpro2J8?t=1211" target=_blank>Link</a></figcaption></figure><figure style=margin-top:0;margin-bottom:40px;margin-right:auto;margin-left:1%;float:left;width:30%><img style=margin-bottom:20px;border-radius:10px src=../../images/deepRlTraining/film_granTurismoSophy.jpg><figcaption align=middle>Sony AI<br>Gran TurismoÂ® Sophy â€¢ <a href="https://www.youtube.com/watch?v=qP1gjgtKyYc&ab_channel=SonyAI" target=_blank>Link</a></figcaption></figure></div><h3 id=end-to-end-deep-reinforcement-learning>End-to-End Deep Reinforcement Learning</h3><h4 id=reinforcement-learning-libraries>Reinforcement Learning Libraries</h4><p>If one wants to rely on already implemented RL algorithms, focusing his efforts on higher level aspects such as policy network architecture, features selection, hyper-parameters tuning, and so on, the best choice is to leverage state-of-the-art RL libraries as the ones shown below. There are many different options, here we list those that, in our experience, are recognized as the leaders in the field, and have been proven to achieve good performances in DIAMBRA Arena environments.</p><p>There are multiple advantages related to the use of these libraries, to name a few: they provide high quality RL algorithms, efficiently implemented and continuously tested, they allow to natively parallelize environment execution, and in some cases they even support distributed training using multiple GPUs in a single workstation or even in cluster contexts.</p><p>The next section provides guidance and examples using some of the options listed down here.</p><div><figure style=margin-top:0;margin-bottom:40px;margin-right:1%;margin-left:3%;float:left;width:30%><img style=margin-bottom:20px;border-radius:10px src=../../images/deepRlTraining/lib_sheeprl.png><figcaption align=middle>SheepRL â€¢ <a href=https://github.com/Eclectic-Sheep/sheeprl/tree/main target=_blank>Link</a></figcaption></figure><figure style=margin-top:0;margin-bottom:40px;margin-right:1%;margin-left:1%;float:left;width:30%><img style=margin-bottom:20px;border-radius:10px src=../../images/deepRlTraining/lib_sb3.png><figcaption align=middle>Stable Baselines 3 â€¢ <a href=https://stable-baselines3.readthedocs.io/en/master/ target=_blank>Link</a></figcaption></figure><figure style=margin-top:0;margin-bottom:40px;margin-right:1%;margin-left:1%;float:left;width:30%><img style=margin-bottom:20px;border-radius:10px src=../../images/deepRlTraining/lib_rayrllib.png><figcaption align=middle>Ray RLlib â€¢ <a href=https://docs.ray.io/en/latest/rllib/index.html target=_blank>Link</a></figcaption></figure></div><h4 id=creating-an-agent>Creating an Agent</h4><div class="notices tip"><p>All the examples presented in these sections (plus additional code) showing how to interface DIAMBRA Arena with the major reinforcement learning libraries, can be found in our open source repository <a href=https://github.com/diambra/agents target=_blank>DIAMBRA Agents</a>.</span></p></div><h5 id=scripted-agents>Scripted Agents</h5><p>The classical way to create an agent able to play a game is to hand-code the rules governing its behavior. These rules can vary from very simple heuristics to very complex behavioral trees, but they all have in common the need of an expert coder that knows the game and is able to distill the key elements of it to craft the scripted bot.</p><p>The following are two examples of (very simple) scripted agents interfaced with our environments, and they are available here: <a href=https://github.com/diambra/agents/tree/main/basic target=_blank>DIAMBRA Agents - Basic</a>.</p><h6 id=no-action-agent>No-Action Agent</h6><p>This agent simply performs the &ldquo;No-Action&rdquo; action at every step. By convention it is the action with index 0, and it needs to be a single value for <code>Discrete</code> action spaces, and a tuple of 0s for <code>MultiDiscrete</code> ones, as shown in the snippet below.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#75715e>#!/usr/bin/env python3</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> diambra.arena
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> diambra.arena <span style=color:#f92672>import</span> SpaceTypes, Roles, EnvironmentSettings
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> diambra.arena.utils.gym_utils <span style=color:#f92672>import</span> available_games
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> random
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> argparse
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>main</span>(game_id<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;random&#34;</span>, test<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>):
</span></span><span style=display:flex><span>    game_dict <span style=color:#f92672>=</span> available_games(<span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> game_id <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;random&#34;</span>:
</span></span><span style=display:flex><span>        game_id <span style=color:#f92672>=</span> random<span style=color:#f92672>.</span>sample(game_dict<span style=color:#f92672>.</span>keys(),<span style=color:#ae81ff>1</span>)[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        game_id <span style=color:#f92672>=</span> opt<span style=color:#f92672>.</span>gameId <span style=color:#66d9ef>if</span> opt<span style=color:#f92672>.</span>gameId <span style=color:#f92672>in</span> game_dict<span style=color:#f92672>.</span>keys() <span style=color:#66d9ef>else</span> random<span style=color:#f92672>.</span>sample(game_dict<span style=color:#f92672>.</span>keys(),<span style=color:#ae81ff>1</span>)[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Settings</span>
</span></span><span style=display:flex><span>    settings <span style=color:#f92672>=</span> EnvironmentSettings()
</span></span><span style=display:flex><span>    settings<span style=color:#f92672>.</span>step_ratio <span style=color:#f92672>=</span> <span style=color:#ae81ff>6</span>
</span></span><span style=display:flex><span>    settings<span style=color:#f92672>.</span>frame_shape <span style=color:#f92672>=</span> (<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    settings<span style=color:#f92672>.</span>role <span style=color:#f92672>=</span> Roles<span style=color:#f92672>.</span>P2
</span></span><span style=display:flex><span>    settings<span style=color:#f92672>.</span>difficulty <span style=color:#f92672>=</span> <span style=color:#ae81ff>4</span>
</span></span><span style=display:flex><span>    settings<span style=color:#f92672>.</span>action_space <span style=color:#f92672>=</span> SpaceTypes<span style=color:#f92672>.</span>MULTI_DISCRETE
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    env <span style=color:#f92672>=</span> diambra<span style=color:#f92672>.</span>arena<span style=color:#f92672>.</span>make(game_id, settings)
</span></span><span style=display:flex><span>    observation, info <span style=color:#f92672>=</span> env<span style=color:#f92672>.</span>reset()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>while</span> <span style=color:#66d9ef>True</span>:
</span></span><span style=display:flex><span>        action <span style=color:#f92672>=</span> env<span style=color:#f92672>.</span>get_no_op_action()
</span></span><span style=display:flex><span>        observation, reward, terminated, truncated, info <span style=color:#f92672>=</span> env<span style=color:#f92672>.</span>step(action)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> terminated <span style=color:#f92672>or</span> truncated:
</span></span><span style=display:flex><span>            observation, info <span style=color:#f92672>=</span> env<span style=color:#f92672>.</span>reset()
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> info[<span style=color:#e6db74>&#34;env_done&#34;</span>] <span style=color:#f92672>or</span> test <span style=color:#f92672>is</span> <span style=color:#66d9ef>True</span>:
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>break</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Close the environment</span>
</span></span><span style=display:flex><span>    env<span style=color:#f92672>.</span>close()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Return success</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
</span></span><span style=display:flex><span>    parser <span style=color:#f92672>=</span> argparse<span style=color:#f92672>.</span>ArgumentParser()
</span></span><span style=display:flex><span>    parser<span style=color:#f92672>.</span>add_argument(<span style=color:#e6db74>&#39;--gameId&#39;</span>, type<span style=color:#f92672>=</span>str, default<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;random&#34;</span>, help<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Game ID&#39;</span>)
</span></span><span style=display:flex><span>    parser<span style=color:#f92672>.</span>add_argument(<span style=color:#e6db74>&#39;--test&#39;</span>, type<span style=color:#f92672>=</span>int, default<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, help<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Test mode&#39;</span>)
</span></span><span style=display:flex><span>    opt <span style=color:#f92672>=</span> parser<span style=color:#f92672>.</span>parse_args()
</span></span><span style=display:flex><span>    print(opt)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    main(opt<span style=color:#f92672>.</span>gameId, bool(opt<span style=color:#f92672>.</span>test))
</span></span></code></pre></div><h6 id=random-agent>Random Agent</h6><p>This agent simply performs a random action at every step. In this case, the sampling method takes care of generating an action that is consistent with the environment action space.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#75715e>#!/usr/bin/env python3</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> diambra.arena
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> diambra.arena <span style=color:#f92672>import</span> SpaceTypes, Roles, EnvironmentSettings
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> diambra.arena.utils.gym_utils <span style=color:#f92672>import</span> available_games
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> random
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> argparse
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>main</span>(game_id<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;random&#34;</span>, test<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>):
</span></span><span style=display:flex><span>    game_dict <span style=color:#f92672>=</span> available_games(<span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> game_id <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;random&#34;</span>:
</span></span><span style=display:flex><span>        game_id <span style=color:#f92672>=</span> random<span style=color:#f92672>.</span>sample(game_dict<span style=color:#f92672>.</span>keys(),<span style=color:#ae81ff>1</span>)[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        game_id <span style=color:#f92672>=</span> opt<span style=color:#f92672>.</span>gameId <span style=color:#66d9ef>if</span> opt<span style=color:#f92672>.</span>gameId <span style=color:#f92672>in</span> game_dict<span style=color:#f92672>.</span>keys() <span style=color:#66d9ef>else</span> random<span style=color:#f92672>.</span>sample(game_dict<span style=color:#f92672>.</span>keys(),<span style=color:#ae81ff>1</span>)[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Settings</span>
</span></span><span style=display:flex><span>    settings <span style=color:#f92672>=</span> EnvironmentSettings()
</span></span><span style=display:flex><span>    settings<span style=color:#f92672>.</span>step_ratio <span style=color:#f92672>=</span> <span style=color:#ae81ff>6</span>
</span></span><span style=display:flex><span>    settings<span style=color:#f92672>.</span>frame_shape <span style=color:#f92672>=</span> (<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    settings<span style=color:#f92672>.</span>role <span style=color:#f92672>=</span> Roles<span style=color:#f92672>.</span>P2
</span></span><span style=display:flex><span>    settings<span style=color:#f92672>.</span>difficulty <span style=color:#f92672>=</span> <span style=color:#ae81ff>4</span>
</span></span><span style=display:flex><span>    settings<span style=color:#f92672>.</span>action_space <span style=color:#f92672>=</span> SpaceTypes<span style=color:#f92672>.</span>MULTI_DISCRETE
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    env <span style=color:#f92672>=</span> diambra<span style=color:#f92672>.</span>arena<span style=color:#f92672>.</span>make(game_id, settings)
</span></span><span style=display:flex><span>    observation, info <span style=color:#f92672>=</span> env<span style=color:#f92672>.</span>reset()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>while</span> <span style=color:#66d9ef>True</span>:
</span></span><span style=display:flex><span>        action <span style=color:#f92672>=</span> env<span style=color:#f92672>.</span>action_space<span style=color:#f92672>.</span>sample()
</span></span><span style=display:flex><span>        observation, reward, terminated, truncated, info <span style=color:#f92672>=</span> env<span style=color:#f92672>.</span>step(action)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> terminated <span style=color:#f92672>or</span> truncated:
</span></span><span style=display:flex><span>            observation, info <span style=color:#f92672>=</span> env<span style=color:#f92672>.</span>reset()
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> info[<span style=color:#e6db74>&#34;env_done&#34;</span>] <span style=color:#f92672>or</span> test <span style=color:#f92672>is</span> <span style=color:#66d9ef>True</span>:
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>break</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Close the environment</span>
</span></span><span style=display:flex><span>    env<span style=color:#f92672>.</span>close()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Return success</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
</span></span><span style=display:flex><span>    parser <span style=color:#f92672>=</span> argparse<span style=color:#f92672>.</span>ArgumentParser()
</span></span><span style=display:flex><span>    parser<span style=color:#f92672>.</span>add_argument(<span style=color:#e6db74>&#39;--gameId&#39;</span>, type<span style=color:#f92672>=</span>str, default<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;random&#34;</span>, help<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Game ID&#39;</span>)
</span></span><span style=display:flex><span>    parser<span style=color:#f92672>.</span>add_argument(<span style=color:#e6db74>&#39;--test&#39;</span>, type<span style=color:#f92672>=</span>int, default<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, help<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Test mode&#39;</span>)
</span></span><span style=display:flex><span>    opt <span style=color:#f92672>=</span> parser<span style=color:#f92672>.</span>parse_args()
</span></span><span style=display:flex><span>    print(opt)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    main(opt<span style=color:#f92672>.</span>gameId, bool(opt<span style=color:#f92672>.</span>test))
</span></span></code></pre></div><p>More complex scripts can be built in similar ways, for example continuously performing user-defined combos moves, or adding some more complex choice mechanics. But this would still require to decide the tactics in advance, properly translating knowledge into code. A different approach would be to leverage reinforcement learning, so that the agent will improve leveraging its own experience.</p><h5 id=deeprl-trained-agents>DeepRL Trained Agents</h5><p>An alternative approach to scripted agents is adopting reinforcement learning, and the following sections provide examples on how to do that with the most important libraries in the domain.</p><p>DIAMBRA Arena natively provides interfaces to SheepRL, Stable Baselines 3, and Ray RLlib, allowing to easily train models with them on our environments. Each library-dedicated page presents some basic and advanced examples.</p><div style=font-size:1.125rem><ul><li><a href=./sheeprl/>SheepRL</a></li><li><a href=./stablebaselines3/>Stable Baselines 3</a></li><li><a href=./rayrllib/>Ray RLlib</a></li></ul></div><div class="notices note"><p>DIAMBRA Arena provides a working interface with Stable Baselines 2 too, but it is deprecated and will be discontinued in the near future.</p></div><footer class=footline></footer></div></div><div id=navigation></div></section><div style=left:-1000px;overflow:scroll;position:absolute;top:-1000px;border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px><div style=border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px></div></div><script src=/js/clipboard.min.js?1718070586></script>
<script src=/js/perfect-scrollbar.min.js?1718070586></script>
<script src=/js/perfect-scrollbar.jquery.min.js?1718070586></script>
<script src=/js/jquery.sticky.js?1718070586></script>
<script src=/js/featherlight.min.js?1718070586></script>
<script src=/js/highlight.pack.js?1718070586></script>
<script>hljs.initHighlightingOnLoad()</script><script src=/js/modernizr.custom-3.6.0.js?1718070586></script>
<script src=/js/learn.js?1718070586></script>
<script src=/js/hugo-learn.js?1718070586></script>
<script src=https://unpkg.com/mermaid@8.8.0/dist/mermaid.min.js></script>
<script>mermaid.initialize({startOnLoad:!0})</script><script>(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-105947713-1","auto"),ga("send","pageview")</script></body></html>