<!doctype html><html lang=en class="js csstransforms3d"><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.112.3"><meta name=description content="Official documentation for DIAMBRA, the platform where coders create AI agents to compete in video games tournaments."><meta name=author content="DIAMBRA Team"><meta name=keywords content="Documentation,Reinforcement Learning,Deep Reinforcement Learning,AI Tournaments,Video Games Environments,RL Environments,DIAMBRA,DIAMBRA Documentation,AI Competitions,Artificial Intelligence"><meta itemprop=name content="DIAMBRA Docs"><meta itemprop=description content="Official documentation for DIAMBRA, the platform where coders create AI agents to compete in video games tournaments."><meta itemprop=image content="https://docs.diambra.ai//images/logoMeta.png"><meta property="og:site_name" content="DIAMBRA Docs"><meta property="og:title" content="DIAMBRA Docs"><meta property="og:description" content="Official documentation for DIAMBRA, the platform where coders create AI agents to compete in video games tournaments."><meta property="og:image" content="https://docs.diambra.ai//images/logoMeta.png"><meta property="og:url" content="https://docs.diambra.ai"><meta property="og:type" content="website"><meta name=publish_date property="og:publish_date" content="2022-01-15T00:00:00-0600"><meta charset=utf-8><link rel=icon href=/images/favicon.png type=image/png><title>Environments :: DIAMBRA Docs</title><link href=/css/nucleus.css?1710219036 rel=stylesheet><link href=/css/fontawesome-all.min.css?1710219036 rel=stylesheet><link href=/css/hybrid.css?1710219036 rel=stylesheet><link href=/css/featherlight.min.css?1710219036 rel=stylesheet><link href=/css/perfect-scrollbar.min.css?1710219036 rel=stylesheet><link href=/css/auto-complete.css?1710219036 rel=stylesheet><link href=/css/atom-one-dark-reasonable.css?1710219036 rel=stylesheet><link href=/css/theme.css?1710219036 rel=stylesheet><link href=/css/tabs.css?1710219036 rel=stylesheet><link href=/css/hugo-theme.css?1710219036 rel=stylesheet><link href=/css/theme-diambra.css?1710219036 rel=stylesheet><script src=/js/jquery-3.3.1.min.js?1710219036></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><style>:root #header+#content>#left>#rlblock_left{display:none!important}</style><style type=text/css>pre code{white-space:pre}</style></head><body data-url=/envs/><nav id=sidebar class=showVisitedLinks><div id=header-wrapper><div id=header><a id=logo href=https://docs.diambra.ai/><img src=https://docs.diambra.ai//images/logo.png></a></div><div class=searchbox><label for=search-by><i class="fas fa-search"></i></label>
<input data-search-input id=search-by type=search placeholder=Search...>
<span data-search-clear><i class="fas fa-times"></i></span></div><script type=text/javascript src=/js/lunr.min.js?1710219036></script>
<script type=text/javascript src=/js/auto-complete.js?1710219036></script>
<script type=text/javascript>var baseurl="https://docs.diambra.ai/"</script><script type=text/javascript src=/js/search.js?1710219036></script></div><section id=homelinks><ul><li><a class=padding href=https://docs.diambra.ai/><i class='fas fa-home'></i> Home</a></li></ul></section><section id=versions class=dropdown><a class=dropdown-toggle>Versions ▼</a><div class=dropdown-content><a href=/>Latest</a>
<a href=/v2.1>2.1</a></div></section><div class=highlightable><ul class=topics><li data-nav-id=/gettingstarted/ title="Getting Started" class=dd-item><a href=/gettingstarted/>Getting Started
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/gettingstarted/examples/ title=Examples class=dd-item><a href=/gettingstarted/examples/>Examples
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/gettingstarted/examples/singleplayerenv/ title="Single Player Environment" class=dd-item><a href=/gettingstarted/examples/singleplayerenv/>Single Player Environment
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/gettingstarted/examples/multiplayerenv/ title="Multi Player Environment" class=dd-item><a href=/gettingstarted/examples/multiplayerenv/>Multi Player Environment
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/gettingstarted/examples/wrappersoptions/ title="Wrappers Options" class=dd-item><a href=/gettingstarted/examples/wrappersoptions/>Wrappers Options
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/gettingstarted/examples/episoderecorder/ title="Episode Recorder" class=dd-item><a href=/gettingstarted/examples/episoderecorder/>Episode Recorder
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/gettingstarted/examples/datasetloader/ title="Dataset Loader" class=dd-item><a href=/gettingstarted/examples/datasetloader/>Dataset Loader
<i class="fas fa-check read-icon"></i></a></li></ul></li></ul></li><li data-nav-id=/envs/ title=Environments class="dd-item
active"><a href=/envs/>Environments
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/envs/games/ title="Games & Specifics" class=dd-item><a href=/envs/games/>Games & Specifics
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/envs/games/doapp/ title="Dead Or Alive ++" class=dd-item><a href=/envs/games/doapp/>Dead Or Alive ++
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/envs/games/sfiii3n/ title="Street Fighter III 3rd Strike" class=dd-item><a href=/envs/games/sfiii3n/>Street Fighter III 3rd Strike
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/envs/games/tektagt/ title="Tekken Tag Tournament" class=dd-item><a href=/envs/games/tektagt/>Tekken Tag Tournament
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/envs/games/umk3/ title="Ultimate Mortal Kombat 3" class=dd-item><a href=/envs/games/umk3/>Ultimate Mortal Kombat 3
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/envs/games/samsh5sp/ title="Samurai Showdown 5 Special" class=dd-item><a href=/envs/games/samsh5sp/>Samurai Showdown 5 Special
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/envs/games/kof98umh/ title="The King of Fighers '98 UMH" class=dd-item><a href=/envs/games/kof98umh/>The King of Fighers '98 UMH
<i class="fas fa-check read-icon"></i></a></li></ul></li></ul></li><li data-nav-id=/wrappers/ title=Wrappers class=dd-item><a href=/wrappers/>Wrappers
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/utils/ title=Utils class=dd-item><a href=/utils/>Utils
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/imitationlearning/ title="Imitation Learning" class=dd-item><a href=/imitationlearning/>Imitation Learning
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/handsonreinforcementlearning/ title="Hands-on Reinforcement Learning" class=dd-item><a href=/handsonreinforcementlearning/>Hands-on Reinforcement Learning
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/handsonreinforcementlearning/sheeprl/ title=SheepRL class=dd-item><a href=/handsonreinforcementlearning/sheeprl/>SheepRL
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/handsonreinforcementlearning/stablebaselines3/ title="Stable Baselines 3" class=dd-item><a href=/handsonreinforcementlearning/stablebaselines3/>Stable Baselines 3
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/handsonreinforcementlearning/rayrllib/ title="Ray RLlib" class=dd-item><a href=/handsonreinforcementlearning/rayrllib/>Ray RLlib
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/competitionplatform/ title="Competition Platform" class=dd-item><a href=/competitionplatform/>Competition Platform
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/competitionplatform/basicagentscript/ title="Basic Agent Script" class=dd-item><a href=/competitionplatform/basicagentscript/>Basic Agent Script
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/competitionplatform/submissionevaluation/ title="Submission Evaluation" class=dd-item><a href=/competitionplatform/submissionevaluation/>Submission Evaluation
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/competitionplatform/howtosubmitanagent/ title="How To Submit An Agent" class=dd-item><a href=/competitionplatform/howtosubmitanagent/>How To Submit An Agent
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/competitionplatform/howtosubmitanagent/submitprebuiltagents/ title="Submit Pre-Built Agents" class=dd-item><a href=/competitionplatform/howtosubmitanagent/submitprebuiltagents/>Submit Pre-Built Agents
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/competitionplatform/howtosubmitanagent/submityourownagent/ title="Submit Your Own Agent" class=dd-item><a href=/competitionplatform/howtosubmitanagent/submityourownagent/>Submit Your Own Agent
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/competitionplatform/howtosubmitanagent/customdependenciesimage/ title="Custom Dependencies Image" class=dd-item><a href=/competitionplatform/howtosubmitanagent/customdependenciesimage/>Custom Dependencies Image
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/competitionplatform/argumentsandcommands/ title="Arguments and Commands" class=dd-item><a href=/competitionplatform/argumentsandcommands/>Arguments and Commands
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/competitionplatform/testyouragentlocally/ title="Test Your Agent Locally" class=dd-item><a href=/competitionplatform/testyouragentlocally/>Test Your Agent Locally
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/projects/ title=Projects class=dd-item><a href=/projects/>Projects
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/projects/marlleaguetraining/ title="MARL - League Training" class=dd-item><a href=/projects/marlleaguetraining/>MARL - League Training
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/projects/rlztournament/ title="RLZ Tournament" class=dd-item><a href=/projects/rlztournament/>RLZ Tournament
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/projects/gamepainter/ title="Game Painter" class=dd-item><a href=/projects/gamepainter/>Game Painter
<i class="fas fa-check read-icon"></i></a></li></ul></li></ul><section id=shortcuts><h3>More</h3><ul><li><a class=padding href=https://diambra.ai target=_blank><i class='fas fa-globe'></i> Website</a></li><li><a class=padding href=https://github.com/diambra/ target=_blank><i class='fab fa-fw fa-github'></i> GitHub</a></li><li><a class=padding href=https://diambra.ai/discord target=_blank><i class='fab fa-discord'></i> Discord</a></li><li><a class=padding href=https://www.twitch.tv/diambra_ai target=_blank><i class='fab fa-twitch'></i> Twitch</a></li><li><a class=padding href=https://www.linkedin.com/company/diambra target=_blank><i class='fab fa-linkedin'></i> Linkedin</a></li><li><a class=padding href=https://www.youtube.com/c/diambra_ai target=_blank><i class='fab fa-youtube'></i> YouTube</a></li><li><a class=padding href=https://twitter.com/diambra_ai target=_blank><i class='fab fa-fw fa-twitter'></i> Twitter</a></li></ul></section><section id=prefooter><hr><ul><li><a class=padding href=# data-clear-history-toggle><i class="fas fa-history fa-fw"></i> Clear History</a></li></ul></section><section id=footer><center><a class=github-button href=https://github.com/diambra/arena/archive/refs/heads/main.zip data-icon=octicon-download aria-label="Download DIAMBRA Arena from GitHub">Download</a>
<a class=github-button href=https://github.com/diambra/arena data-icon=octicon-star data-show-count=true aria-label="Star DIAMBRA Arena on GitHub">Star</a>
<a class=github-button href=https://github.com/diambra/arena/fork data-icon=octicon-repo-forked data-show-count=true aria-label="Fork DIAMBRA Arena on GitHub">Fork</a></center>
<script async defer src=https://buttons.github.io/buttons.js></script></section></div></nav><section id=body><div id=overlay></div><div class="padding highlightable"><div><div id=top-bar><div id=breadcrumbs itemscope itemtype=http://data-vocabulary.org/Breadcrumb><span id=sidebar-toggle-span><a href=# id=sidebar-toggle data-sidebar-toggle><i class="fas fa-bars"></i></a></span>
<span id=toc-menu><i class="fas fa-list-alt"></i></span>
<span class=links><a href=/>Home</a> > Environments</span></div><div class=progress><div class=wrapper><nav id=TableOfContents><ul><li><ul><li><a href=#index>Index</a></li><li><a href=#overview>Overview</a></li><li><a href=#interaction-basics>Interaction Basics</a></li><li><a href=#settings>Settings</a></li><li><a href=#action-spaces>Action Space(s)</a></li><li><a href=#observation-space>Observation Space</a></li><li><a href=#reward-function>Reward Function</a></li></ul></li></ul></nav></div></div></div></div><div id=head-tags></div><div id=body-inner><h1>Environments</h1><h3 id=index>Index</h3><div style=font-size:1.125rem><ul><li><a href=./#overview>Overview</a></li><li><a href=./#interaction-basics>Interaction Basics</a></li><li><a href=./#settings>Settings</a><ul><li><a href=./#environment-settings>Environment Settings</a></li><li><a href=./#episode-settings>Episode Settings</a><ul><li><a href=./#game-settings>Game Settings</a></li><li><a href=./#player-settings>Player Settings</a></li></ul></li></ul></li><li><a href=./#action-spaces>Action Space(s)</a></li><li><a href=./#observation-space>Observation Space</a><ul><li><a href=./#global>Global</a></li><li><a href=./#player-specific>Player Specific</a></li></ul></li><li><a href=./#reward-function>Reward Function</a></li></ul></div><p>This page describes in details all general aspects related to DIAMBRA Arena environments. For game-specific details visit <a href=./games>Games & Specifics</a> page.</p><h3 id=overview>Overview</h3><p>DIAMBRA Arena is a software package featuring a collection of high-quality environments for Reinforcement Learning research and experimentation. It provides a standard interface to popular arcade emulated video games, offering a Python API fully compliant with OpenAI Gym/Gymnasium format, that makes its adoption smooth and straightforward.</p><p>It supports all major Operating Systems (Linux, Windows and MacOS) and can be easily installed via Python PIP, as described in the <a href=../#installation>installation section</a>. It is completely free to use, the user only needs to register on the official website.</p><p>In addition, its <a href=https://github.com/diambra/arena target=_blank>GitHub repository</a> provides a collection of examples covering main use cases of interest that can be run in just a few steps.</p><h4 id=main-features>Main Features</h4><p>All environments are episodic Reinforcement Learning tasks, with discrete actions (gamepad buttons) and observations composed by screen pixels plus additional numerical data (RAM states like characters health bars or characters stage side).</p><p>They all support both single player (1P) as well as two players (2P) mode, making them the perfect resource to explore all the following Reinforcement Learning subfields:</p><div style=margin-bottom:0><figure style=padding:2px;margin-right:auto;margin-left:auto;float:left;min-width:110px;max-width:15%;min-height:120px><img style=margin-top:0;margin-bottom:10px;border-radius:10px src=/images/home/AIvsCOM.png><figcaption align=middle>Standard RL</figcaption></figure><figure style=padding:2px;margin-right:auto;margin-left:auto;float:left;min-width:110px;max-width:15%;min-height:120px><img style=margin-top:0;margin-bottom:10px;border-radius:10px src=/images/home/AIvsAI.png><figcaption align=middle>Competitive Multi-Agent</figcaption></figure><figure style=padding:2px;margin-right:auto;margin-left:auto;float:left;min-width:110px;max-width:15%;min-height:120px><img style=margin-top:0;margin-bottom:10px;border-radius:10px src=/images/home/AIvsHUM.png><figcaption align=middle>Competitive Human-Agent</figcaption></figure><figure style=padding:2px;margin-right:auto;margin-left:auto;float:left;min-width:110px;max-width:15%;min-height:120px><img style=margin-top:0;margin-bottom:10px;border-radius:10px src=/images/home/SP.png><figcaption align=middle>Self-Play</figcaption></figure><figure style=padding:2px;margin-right:auto;margin-left:auto;float:left;min-width:110px;max-width:15%;min-height:120px><img style=margin-top:0;margin-bottom:10px;border-radius:10px src=/images/home/IL.png><figcaption align=middle>Imitation Learning</figcaption></figure><figure style=padding:2px;margin-right:auto;margin-left:auto;float:left;min-width:110px;max-width:15%;min-height:120px><img style=margin-top:0;margin-bottom:10px;border-radius:10px src=/images/home/HITL.png><figcaption align=middle>Human-in-the-Loop</figcaption></figure></div><h4 id=available-games>Available Games</h4><p>Interfaced games have been selected among the most popular fighting retro-games. While sharing the same fundamental mechanics, they provide different challenges, with specific features such as different type and number of characters, how to perform combos, health bars recharging, etc.</p><p>Whenever possible, games are released with all hidden/bonus characters unlocked.</p><p>Additional details can be found in their <a href=./games/>dedicated section</a>.</p><div><figure style=margin-right:1%;margin-left:auto;float:left;width:15%><a href=./games/><img style=margin-top:0;margin-bottom:30px;border-radius:10px src=/images/envs/doapp.jpg></a></figure><figure style=margin-right:1%;margin-left:1%;float:left;width:15%><a href=./games/><img style=margin-top:0;margin-bottom:30px;border-radius:10px src=/images/envs/sfiii3n.jpg></a></figure><figure style=margin-right:1%;margin-left:1%;float:left;width:15%><a href=./games/><img style=margin-top:0;margin-bottom:30px;border-radius:10px src=/images/envs/tektagt.jpg></a></figure><figure style=margin-right:1%;margin-left:1%;float:left;width:15%><a href=./games/><img style=margin-top:0;margin-bottom:30px;border-radius:10px src=/images/envs/umk3.jpg></a></figure><figure style=margin-right:1%;margin-left:1%;float:left;width:15%><a href=./games/><img style=margin-top:0;margin-bottom:30px;border-radius:10px src=/images/envs/samsh5sp.jpg></a></figure><figure style=margin-right:auto;margin-left:1%;float:left;width:15%><a href=./games/><img style=margin-top:0;margin-bottom:30px;border-radius:10px src=/images/envs/kof98umh.jpg></a></figure></div><h3 id=interaction-basics>Interaction Basics</h3><p>DIAMBRA Arena Environments usage follows the standard RL interaction framework: the agent sends an action to the environment, which process it and performs a transition accordingly, from the starting state to the new state, returning the observation and the reward to the agent to close the interaction loop. The figure below shows this typical interaction scheme and data flow.</p><figure style=margin-bottom:0;margin-top:0;margin-right:auto;margin-left:auto;width:80%><img src=../images/envs/basicUsage.png style=margin-bottom:20px><figcaption align=middle>Scheme of Agent-Environment Interaction</figcaption></figure><p>The shortest snippet for a complete basic execution of an environment consists of just a few lines of code, and is presented in the code block below:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#75715e>#!/usr/bin/env python3</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> diambra.arena
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>main</span>():
</span></span><span style=display:flex><span>    <span style=color:#75715e># Environment creation</span>
</span></span><span style=display:flex><span>    env <span style=color:#f92672>=</span> diambra<span style=color:#f92672>.</span>arena<span style=color:#f92672>.</span>make(<span style=color:#e6db74>&#34;doapp&#34;</span>, render_mode<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;human&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Environment reset</span>
</span></span><span style=display:flex><span>    observation, info <span style=color:#f92672>=</span> env<span style=color:#f92672>.</span>reset(seed<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Agent-Environment interaction loop</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>while</span> <span style=color:#66d9ef>True</span>:
</span></span><span style=display:flex><span>        <span style=color:#75715e># (Optional) Environment rendering</span>
</span></span><span style=display:flex><span>        env<span style=color:#f92672>.</span>render()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Action random sampling</span>
</span></span><span style=display:flex><span>        actions <span style=color:#f92672>=</span> env<span style=color:#f92672>.</span>action_space<span style=color:#f92672>.</span>sample()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Environment stepping</span>
</span></span><span style=display:flex><span>        observation, reward, terminated, truncated, info <span style=color:#f92672>=</span> env<span style=color:#f92672>.</span>step(actions)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Episode end (Done condition) check</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> terminated <span style=color:#f92672>or</span> truncated:
</span></span><span style=display:flex><span>            observation, info <span style=color:#f92672>=</span> env<span style=color:#f92672>.</span>reset()
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>break</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Environment shutdown</span>
</span></span><span style=display:flex><span>    env<span style=color:#f92672>.</span>close()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Return success</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
</span></span><span style=display:flex><span>    main()</span></span></code></pre></div><div class="notices note"><p>More complex and complete examples can be found in the <a href=../gettingstarted/examples/>Examples</a> section.</p></div><h3 id=settings>Settings</h3><p>All environments have different options that can be specified using a dedicated <code>EnvironmentSettings</code> class. They are nested as follows:</p><ul><li><span style=color:#333;font-weight:bolder>Environment settings</span>: defined only when the environment is instantiated, they never change throughout the agent-environment interaction (e.g. the action space or the frame size)<ul><li><span style=color:#333;font-weight:bolder>Episode settings</span>: defined first when the environment is instantiated, they can be changed each time a new episode starts, i.e. at every environment <code>reset</code> call, passing a dictionary containing the key-value pairs for the settings of interest through the <code>options</code> keyword argument. These settings are further divided in:<ul><li><span style=color:#333;font-weight:bolder>Game settings</span>: they specify features of the game (e.g. difficulty level)</li><li><span style=color:#333;font-weight:bolder>Player settings</span>: they specify player-related aspects (e.g. selected character and its outfits)</li></ul></li></ul></li></ul><p>Settings specifications when instantiating the environment is done by passing the <code>EnvironmentSettings</code> class, properly filled, to the environment <code>make</code> call as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> diambra.arena <span style=color:#f92672>import</span> EnvironmentSettings
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Settings specification</span>
</span></span><span style=display:flex><span>settings <span style=color:#f92672>=</span> EnvironmentSettings()
</span></span><span style=display:flex><span>settings<span style=color:#f92672>.</span>setting_1 <span style=color:#f92672>=</span> value_1
</span></span><span style=display:flex><span>settings<span style=color:#f92672>.</span>setting_2 <span style=color:#f92672>=</span> value_2
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>env <span style=color:#f92672>=</span> diambra<span style=color:#f92672>.</span>arena<span style=color:#f92672>.</span>make(<span style=color:#e6db74>&#34;doapp&#34;</span>, settings)
</span></span></code></pre></div><p>The first argument is the <code>game_id</code> string, it specifies the game to execute among those available (see <a href=./games/>games list</a> for details).</p><p>Episode settings specification at reset is done by passing the <code>episode_settings</code> dictionary to the environment <code>reset</code> call as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Episode settings</span>
</span></span><span style=display:flex><span>episode_settings <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>  setting_1: value_1,
</span></span><span style=display:flex><span>  setting_2: value_2,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>env<span style=color:#f92672>.</span>reset(options<span style=color:#f92672>=</span>episode_settings)
</span></span></code></pre></div><p>Some of them are shared among all environments and are presented here below, while others are specific to the selected game and can be found in the game-specific pages listed <a href=./games/>here.</a></p><p>The tables in the next sections lists all the attributes of the setting classes.</p><h5 id=use-dictionaries-to-specify-settings>Use dictionaries to specify settings</h5><p>As for previous versions of the library, it is also possible to specify environment settings through a dictionary and use a dedicated function to load it into the <code>EnvironmentSettings</code> class:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> diambra.arena <span style=color:#f92672>import</span> EnvironmentSettings, load_settings_flat_dict
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Settings specification</span>
</span></span><span style=display:flex><span>settings <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>  setting_1: value_1,
</span></span><span style=display:flex><span>  setting_2: value_2,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>settings <span style=color:#f92672>=</span> load_settings_flat_dict(EnvironmentSettings, settings)
</span></span><span style=display:flex><span>env <span style=color:#f92672>=</span> diambra<span style=color:#f92672>.</span>arena<span style=color:#f92672>.</span>make(<span style=color:#e6db74>&#34;doapp&#34;</span>, settings)
</span></span></code></pre></div><div class="notices note"><p>When using multi-agents (two players) environments, the settings class to be passed to the environment <code>make</code> method is the <code>EnvironmentSettingsMultiAgent</code> instead of <code>EnvironmentSettings</code>, while all the attributes will remain the same.</p></div><div class="notices note"><p>Following OpenAI Gym/Gymnasium standard, also the <code>seed</code> can be specified at <code>reset</code> using <code>env.reset(seed=seed, options=episode_settings)</code>, but please note that:<br> <span style=color:#333;font-weight:bolder>•</span> It can be directly passed through the <code>settings</code> dictionary when the environment is instantiated and the environment will take care of setting it at the first <code>reset</code> call<br> <span style=color:#333;font-weight:bolder>•</span> When explicitly passed to the <code>reset</code> keyword argument, it should only be passed to the very first <code>reset</code> method call and never after it</p></div><div class="notices tip"><p>Two ready-to-use examples showing how environment settings are used can be found <a href=../gettingstarted/examples/singleplayerenv/>here</a> and <a href=../gettingstarted/examples/multiplayerenv/>here</a>.</p></div><h4 id=environment-settings>Environment Settings</h4><table><thead><tr><th><strong><span style=color:#5b5b60>Name</span></strong></th><th><strong><span style=color:#5b5b60>Type</span></strong></th><th><strong><span style=color:#5b5b60>Default Value(s)</span></strong></th><th><strong><span style=color:#5b5b60>Value Range</span></strong></th><th><strong><span style=color:#5b5b60>Description</span></strong></th></tr></thead><tbody><tr><td><code>frame_shape</code></td><td><code>tuple</code> of three <code>int</code> (H, W, C)</td><td>(0, 0, 0)</td><td>H, W: [0, 512]<br>C: 0 or 1</td><td>If active, resizes the frame and/or converts it from RGB to grayscale.<br>Combinations:<br>(0, 0, 0) - Deactivated;<br>(H, W, 0) - RBG frame resized to H X W;<br>(0, 0, 1) - Grayscale frame;<br>(H, W, 1) - Grayscale frame resized to H X W.</td></tr><tr><td><code>action_space*</code></td><td><code>SpaceTypes</code></td><td><code>MULTI_DISCRETE</code></td><td><code>DISCRETE</code> / <code>MULTI_DISCRETE</code></td><td>Defines the type of the action space</td></tr><tr><td><code>n_players</code></td><td><code>int</code></td><td>1</td><td>[1, 2]</td><td>Selects single player or two players mode</td></tr><tr><td><code>step_ratio</code></td><td><code>int</code></td><td>6</td><td>[1, 6]</td><td>Defines how many steps the game (emulator) performs for every environment step</td></tr><tr><td><code>splash_screen</code></td><td><code>bool</code></td><td><code>True</code></td><td><code>True</code> / <code>False</code></td><td>Activates displaying the splash screen when launching the environment</td></tr></tbody></table><div class="notices note"><p>*: must be provided as tuples of two elements (for <code>agent_0</code> and <code>agent_1</code> respectively) when using the environments in two players mode.</p></div><h4 id=episode-settings>Episode Settings</h4><h5 id=game-settings>Game Settings</h5><table><thead><tr><th><strong><span style=color:#5b5b60>Name</span></strong></th><th><strong><span style=color:#5b5b60>Type</span></strong></th><th><strong><span style=color:#5b5b60>Default Value(s)</span></strong></th><th><strong><span style=color:#5b5b60>Value Range</span></strong></th><th><strong><span style=color:#5b5b60>Description</span></strong></th></tr></thead><tbody><tr><td><code>difficulty</code></td><td><code>None</code> U <code>int</code></td><td><code>None</code></td><td>Game-specific min and max values allowed</td><td>Specifies game difficulty (1P only)</td></tr><tr><td><code>continue_game</code></td><td><code>float</code></td><td>0.0</td><td>[0.0, 1.0]: probability of continuing game at game over<br><code>int(abs(-inf, -1.0])</code>: number of continues at game over before episode to be considered done</td><td>Defines if and how to allow ”Continue” when the agent is about to face the game over condition</td></tr><tr><td><code>show_final</code></td><td><code>bool</code></td><td><code>False</code></td><td><code>True</code> / <code>False</code></td><td>Activates displaying of final animation when game is completed</td></tr></tbody></table><p>Other variable game settings are found in the game-specific pages where applicable.</p><h5 id=player-settings>Player Settings</h5><p>Environment settings depending on the specific game and shared among all of them are reported in the table below. Additional ones (if present) are reported in game-dedicated pages.</p><table><thead><tr><th><strong><span style=color:#5b5b60>Name</span></strong></th><th><strong><span style=color:#5b5b60>Type</span></strong></th><th><strong><span style=color:#5b5b60>Default Value(s)</span></strong></th><th><strong><span style=color:#5b5b60>Value Range</span></strong></th><th><strong><span style=color:#5b5b60>Description</span></strong></th></tr></thead><tbody><tr><td><code>role*</code></td><td><code>None</code> U <code>Roles</code></td><td><code>None</code></td><td><code>P1</code> (left), <code>P2</code> (right), <code>None</code> (50% P1, 50% P2)</td><td>Selects role for the player, which also affects the side positioning at round starts</td></tr><tr><td><code>characters*</code></td><td><code>None</code> U <code>str</code> U <code>tuple</code> of maximum three <code>str</code></td><td><code>None</code></td><td>Game-specific lists of characters that can be selected</td><td>Specifies character(s) to use</td></tr><tr><td><code>outfits*</code></td><td><code>int</code></td><td>1</td><td>Game-specific min and max values allowed</td><td>Defines the number of outfits to draw from at character selection</td></tr></tbody></table><figure style=margin-bottom:0;margin-top:0;margin-right:auto;margin-left:auto;width:60%><img src=../images/envs/outfits.png style=margin-bottom:20px><figcaption align=middle>Example of Dead or Alive ++ available outfits for Kasumi</figcaption></figure><p>Other variable player settings are found in the game-specific pages where applicable.</p><div class="notices note"><p>*: must be provided as tuples of two elements (for <code>agent_0</code> and <code>agent_1</code> respectively) when using the environments in two players mode.</p></div><div class="notices note"><p><code>None</code> values specify a <code>Random</code> behavior for the correspondent parameter.</p></div><h3 id=action-spaces>Action Space(s)</h3><p>Actions of the interfaced games can be grouped in two categories: move actions (Up, Left, etc.) and attack ones (Punch, Kick, etc.). DIAMBRA Arena provides two different action spaces: <a href=https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/spaces/discrete.py target=_blank>Discrete</a> and <a href=https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/spaces/multi_discrete.py target=_blank>MultiDiscrete</a>. The former is a single list composed by the union of move and attack actions (of type <code>gymnasium.spaces.Discrete</code>), while the latter consists of two sets combined, for move and attack actions respectively (of type <code>gymnasium.spaces.MultiDiscrete</code>). The complete visual description of available action spaces is shown in the figure below, where both choices are presented via the correspondent gamepad buttons configuration for Dead Or Alive ++.</p><p>When run in 2P mode, the environment is provided with a <a href=https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/spaces/dict.py target=_blank>Dictionary</a> action space (type <code>gymnasium.spaces.Dict</code>) populated with two items, identified by keys <code>agent_0</code> and <code>agent_1</code>, whose values are either <code>gymnasium.spaces.Discrete</code> or <code>gymnasium.spaces.MultiDiscrete</code> as described above.</p><p>Each game has specific action spaces since attack buttons (and their combinations) are, in general, game-dependent. For this reason, in each game-dedicated page, a table like the one found below is reported, describing both actions spaces for the specific game.</p><p>In <a href=https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/spaces/discrete.py target=_blank>Discrete</a> action spaces:</p><ul><li>There is only one ”no-op” action, that covers both the ”no-move” and ”no-attack” actions.</li><li>The total number of actions available is N<sub>m</sub> + N<sub>a</sub> − 1 where N<sub>m</sub> is the number of move actions (no-move included) and N<sub>a</sub> is the number of attack actions (no-attack included).</li><li>Only one action, either move or attack, can be sent for each environment step.</li></ul><p>In <a href=https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/spaces/multi_discrete.py target=_blank>MultiDiscrete</a> action spaces:</p><ul><li>There is only one ”no-op” action, that covers both the ”no-move” and ”no-attack” actions.</li><li>The total number of actions available is N<sub>m</sub> × N<sub>a</sub>.</li><li>Both move and attack actions can be sent at the same time for each environment step.</li></ul><p>All and only meaningful actions are made available per each game: they are sufficient to cover the entire spectrum of moves and combos for all the available characters. If a specific game has Button-1 and Button-2 among its available actions, and not Button-1 + Button-2, it means that the latter has no effect in any circumstance, considering all characters in all conditions.</p><p>Some actions (especially attack buttons combinations) may have no effect for some of the characters: in some games combos requiring attack buttons combinations are valid only for a subset of characters.</p><figure style=margin-bottom:20px;margin-top:0;margin-right:auto;margin-left:auto;width:60%><img src=../images/envs/actionSpaces.png style=margin-bottom:20px><figcaption align=middle>Example of Dead Or Alive ++ Action Spaces</figcaption></figure><p>For every game, a table containing the following info is reported. It provides numerical details about action spaces sizes.</p><table><thead><tr><th><strong><span style=color:#5b5b60>Type</span></strong></th><th><strong><span style=color:#5b5b60>Space Size (Number of Actions)</span></strong></th></tr></thead><tbody><tr><td><a href=https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/spaces/discrete.py target=blank_>Discrete</a> / <a href=https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/spaces/multi_discrete.py target=blank_>MultiDiscrete</a></td><td>Total number of actions available, divided in move and attack actions</td></tr></tbody></table><h3 id=observation-space>Observation Space</h3><p>Environment observations are composed by two main elements: a visual one (the game frame) and an aggregation of quantitative values called RAM states (stage number, health values, etc.). Both of them are exposed through an observation space of type <a href=https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/spaces/dict.py target=blank_><code>gym.spaces.Dict</code></a>. It consists of global elements and player-specific ones, they are presented and described in the tables below. To give additional context, next figure shows an example of Dead Or Alive ++ observation where some of the RAM States are highlighted, superimposed on the game frame.</p><p>Each game specifies and extends the set presented here with its custom one, described in the game-dedicated page.</p><figure style=margin-bottom:0;margin-top:0;margin-right:auto;margin-left:auto><img src=../images/envs/doappData.png style=margin-bottom:20px><figcaption align=middle>An example of Dead Or Alive ++ RAM states</figcaption></figure><h4 id=global>Global</h4><p>Global elements of the observation space are unrelated to the player and they are currently limited to those presented and described in the following table. The same table is found on each game-dedicated page reporting its specs:</p><table><thead><tr><th><strong><span style=color:#5b5b60>Key</span></strong></th><th><strong><span style=color:#5b5b60>Type</span></strong></th><th><strong><span style=color:#5b5b60>Value Range</span></strong></th><th><strong><span style=color:#5b5b60>Description</span></strong></th></tr></thead><tbody><tr><td><code>frame</code></td><td><a href=https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/spaces/box.py target=blank_>Box</a></td><td>Game-specific min and max values for each dimension</td><td>Latest game frame (RGB pixel screen)</td></tr><tr><td><code>stage</code></td><td><a href=https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/spaces/box.py target=blank_>Box</a></td><td>Game-specific min and max values</td><td>Current stage of the game</td></tr><tr><td><code>timer</code></td><td><a href=https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/spaces/box.py target=blank_>Box</a></td><td>[0, round duration]</td><td>Round time remaining</td></tr></tbody></table><h4 id=player-specific>Player specific</h4><p>Player-specific observations are nested under the key indicating the player they are referred to (i.e. <code>"P1"</code> and <code>"P2"</code>). A code example is shown below for the <code>side</code> RAM state of the two players:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># P1 side</span>
</span></span><span style=display:flex><span>P1_side <span style=color:#f92672>=</span> observation[<span style=color:#e6db74>&#34;P1&#34;</span>][<span style=color:#e6db74>&#34;side&#34;</span>]
</span></span><span style=display:flex><span><span style=color:#75715e># P2 side</span>
</span></span><span style=display:flex><span>P2_side <span style=color:#f92672>=</span> observation[<span style=color:#e6db74>&#34;P2&#34;</span>][<span style=color:#e6db74>&#34;side&#34;</span>]
</span></span></code></pre></div><p>Typical values that are available for each game are reported and described in the table below. The same table is found in every game-dedicated page, specifying and extending (if needed) the observation elements set.</p><table><thead><tr><th><strong><span style=color:#5b5b60>Key</span></strong></th><th><strong><span style=color:#5b5b60>Type</span></strong></th><th><strong><span style=color:#5b5b60>Value Range</span></strong></th><th><strong><span style=color:#5b5b60>Description</span></strong></th></tr></thead><tbody><tr><td><code>side</code></td><td><a href=https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/spaces/discrete.py target=blank_>Discrete</a> (Binary)</td><td>[0, 1]</td><td>Side of the stage where the player is<br>0: Left, 1: Right</td></tr><tr><td><code>wins</code></td><td><a href=https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/spaces/box.py target=blank_>Box</a></td><td>[0, max number of rounds]</td><td>Number of rounds won by the player for the current stage</td></tr><tr><td><code>character</code></td><td><a href=https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/spaces/discrete.py target=blank_>Discrete</a></td><td>[0, max number of characters - 1]</td><td>Index of character in use</td></tr><tr><td><code>health</code></td><td><a href=https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/spaces/box.py target=blank_>Box</a></td><td>[0, max health value]</td><td>Health bar value</td></tr></tbody></table><div class="notices note"><p>Additional observations, both new and derived from specific processing of the above ones, can be obtained via the wide choice of <a href=../wrappers/>Environment Wrappers</a>, see the dedicated page for details.</p></div><h3 id=reward-function>Reward Function</h3><p>The default reward is defined as a function of characters health values so that, qualitatively, damage suffered by the agent corresponds to a negative reward, and damage inflicted to the opponent corresponds to a positive reward. The quantitative, general and formal reward function definition is as follows:</p><p>$$
\begin{equation}
R_t = \sum_i^{0,N_c}\left(\bar{H_i}^{t^-} - \bar{H_i}^{t} - \left(\hat{H_i}^{t^-} - \hat{H_i}^{t}\right)\right)
\end{equation}
$$</p><p>Where:</p><ul><li>$\bar{H}$ and $\hat{H}$ are health values for opponent’s character(s) and agent’s one(s) respectively;</li><li>$t^-$ and $t$ are used to indicate conditions at ”state-time” and at ”new state-time” (i.e. before and after environment step);</li><li>$N_c$ is the number of characters taking part in a round. Usually is $N_c = 1$ but there are some games where multiple characters are used, with the additional possible option of alternating them during gameplay, like Tekken Tag Tournament where 2 characters have to be selected and two opponents are faced every round (thus $N_c = 2$);</li></ul><p>The lower and upper bounds for the episode total cumulative reward are defined in the equations (Eqs. 2) below. They consider the default reward function for game execution with Continue Game option set equal to 0.0 (Continue not allowed).</p><p>$$
\begin{equation}
\begin{gathered}
\min{\sum_t^{0,T_s}R_t} = - N_c \left( \left(N_s-1\right) \left(N_r-1\right) + N_r\right) \Delta H \\
\max{\sum_t^{0,T_s}R_t} = N_c N_s N_r \Delta H
\end{gathered}
\end{equation}
$$</p><p>Where:</p><ul><li>$N_r$ is the number of rounds to win (or lose) in order to win (or lose) a stage;</li><li>$T_s$ is the terminal state, reached when either $N_r$ rounds are lost (for both 1P and 2P mode) or game is cleared (for 1P mode only);</li><li>$t$ represents the environment step and for an episode goes from 0 to $T_s$;</li><li>$N_s$ is the maximum number of stages the agent can play before the game reaches $T_s$.</li><li>$\Delta H = H_{max} - H_{min}$ is the difference between the maximum and the mimnimum health values for the given game; ususally, but not always, $H_{min} = 0$.</li></ul><p>For 1P mode $N_s$ is game-dependent, while for 2P mode $N_s=1$, meaning the episode always ends after a single stage (so after $N_r$ rounds have been won / lost be the same player, either <code>agent_0</code> or <code>agent_1</code>).</p><p>For 2P mode, <code>agent_0</code> reward is defined as $R$ in the reward Eq. 1 and <code>agent_1</code> reward is equal to $-R$ (zero-sum games). Eq. 1 describes the default reward function. It is of course possible to tweak it at will by means of custom <a href=../wrappers/#reward-wrappers>Reward Wrappers</a>.</p><p>The minimum and maximum total cumulative reward for the round can be <span style=color:#333;font-weight:bolder>different than</span> $N_c\Delta H$ in some cases. This may happen because:</p><ul><li>When multiple characters are used at the same time, the <code>round_done</code> condition can be different for different games (e.g. either at least one character has zero health or all characters have zero health) impacting on the amount of reward collected.</li><li>For some games, health bars can be recharged (e.g. the character in background in Tekken Tag Tournament, or Gill&rsquo;s resurrection move in Street Fighter III), making available an extra amount of reward to be collected or lost in that round.</li><li>For some games, in some stages, additional opponents may be faced (opponent $N_c$ not constant through stages), making available an extra amount of reward to be collected (e.g. the endurance stages in Ultimate Mortal Kombat 3).</li><li>For some games, not all characters share the same maximum health. $H_{max}$ and $H_{min}$ are always the extremes for a given game, among all characters.</li></ul><p>Lower and upper bounds of episode total cumulative reward may, in some cases, deviate from what defined by Eqs. 2, because:</p><ul><li>The absolute value of minimum / maximum total cumulative reward for the round can be different from $N_c\Delta H$ (see above).</li><li>For some games, $N_r$ is not the same for all the stages (1P mode only), for example for Tekken Tag Tournament the final stage is made of a single round while all previous ones require two wins.</li></ul><p>Please note that the maximum cumulative reward (for 1P mode) is obtained when clearing the game winning all rounds with a perfect ($\max{\sum_t^{0,T_s}R_t}\Rightarrow$ game completed), but the vice versa is not true. In fact, not necessarily the higher number of stages won, the higher is the total cumulative reward ($\max{\sum_t^{0,T_s}R_t}\not\propto$ stage reached, game completed $\nRightarrow\max{\sum_t^{0,T_s}R_t}$). Somehow counter intuitively, in order to obtain the lowest possible total cumulative reward the agent is supposed to reach the final stage (collecting negative rewards in all previous ones) before loosing by $N_r$ perfects.</p><h5 id=normalized-reward>Normalized Reward</h5><p>If a normalized reward is considered, the total cumulative reward equation becomes:</p><p>$$
\begin{equation}
R_t = \frac{\sum_i^{0,N_c}\left(\bar{H_i}^{t^-} - \bar{H_i}^{t} - \left(\hat{H_i}^{t^-} - \hat{H_i}^{t}\right)\right)}{N_k \Delta H}
\end{equation}
$$</p><p>With the following additional term at the denominator:</p><ul><li>$N_k$ is the reward normalization factor defined through our <a href=/wrappers/#normalize-reward>reward nomralization wrapper</a>.</li></ul><p>The normalization term at the denominator ensures that a round won with a perfect (i.e. without losing any health), generates always the same maximum total cumulative reward (for the round) accross all games, equal to $N_c/N_k$.</p><footer class=footline></footer></div></div><div id=navigation></div></section><div style=left:-1000px;overflow:scroll;position:absolute;top:-1000px;border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px><div style=border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px></div></div><script src=/js/clipboard.min.js?1710219036></script>
<script src=/js/perfect-scrollbar.min.js?1710219036></script>
<script src=/js/perfect-scrollbar.jquery.min.js?1710219036></script>
<script src=/js/jquery.sticky.js?1710219036></script>
<script src=/js/featherlight.min.js?1710219036></script>
<script src=/js/highlight.pack.js?1710219036></script>
<script>hljs.initHighlightingOnLoad()</script><script src=/js/modernizr.custom-3.6.0.js?1710219036></script>
<script src=/js/learn.js?1710219036></script>
<script src=/js/hugo-learn.js?1710219036></script>
<script src=https://unpkg.com/mermaid@8.8.0/dist/mermaid.min.js></script>
<script>mermaid.initialize({startOnLoad:!0})</script><script>(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-105947713-1","auto"),ga("send","pageview")</script></body></html>