---
date: 2024-03-24T21:57:00
title: Multi Player Environment
weight: 20
---

This example focuses on:

- Two players mode environment usage (Competitive Multi-Agent, SelfPlay, Competitive Human-Agent)
- Environment settings configuration
- Agent - Environment interaction loop
- Gym observation visualization

{{% notice tip %}}
A dedicated section describing environment settings is presented <a href="../../../envs/#settings">here</a>.
{{% /notice %}}

{{< github_code "https://raw.githubusercontent.com/diambra/arena/main/examples/multi_player_env.py" >}}

{{% notice note %}}
You can employ a single trained agent to play against itself in a two-player game setting. To do this effectively, you must separate the observations for each player, ensuring they are formatted correctly according to the model's training configuration. Additionally, actions generated by the model for each player need to be handled distinctly to maintain the integrity of the game's mechanics.
<br><br>
The following example demonstrates utilizing a single model for self-play within a two-player environment. It emphasizes the importance of correctly segregating observations and actions for both players:
<br><br>
This illustration assumes that the model was trained with both flatten and role_relative options set to True. Should your model's training settings differ, adjustments to the handling of observations and actions will be necessary to align with those specific configurations.
{{% /notice %}}

{{< github_code "https://raw.githubusercontent.com/diambra/arena/main/examples/multi_player_trained_agent_selfplay_env.py" >}}